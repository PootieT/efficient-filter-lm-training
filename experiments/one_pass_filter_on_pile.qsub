#!/bin/bash -l

# Set SCC project
#$ -P ds563

# Specify hard time limit for the job.
#   The job will be aborted if it runs longer than this time.
#   The default time is 12 hours
#$ -l h_rt=24:00:00

# Send an email when the job finishes or if it is aborted (by default no email is sent).
######$ -m ea

# Give job a name
#$ -N 'FT-sweep'

# Combine output and error files into a single file
#$ -j y
#$ -o log

# request 6 cores, each with 6 GB RAM at least
#$ -pe omp 4
####$ -l mem_per_core=6G

# Submit an array job with 5 tasks
#$ -t 1-1

# Keep track of information related to the current job
echo "=========================================================="
echo "Start date : $(date)"
echo "Job name : $JOB_NAME"
echo "Job ID : $JOB_ID  $SGE_TASK_ID"
echo "=========================================================="
nvidia-smi

module load anaconda3/5.2.0
source activate /projectnb/llamagrp/peter/CS543-final-project/envs
export PYTHONPATH="${PYTHONPATH}:/projectnb/llamagrp/peter/CS543-final-project"

#index=$(($SGE_TASK_ID-1))
index=35

ROOT="/projectnb2/llamagrp/peter/CS543-final-project"
RUN_NAME="baseline"
CACHE_SIZES=(\
100 100 100 100 100 100 100 100 100 \
300 300 300 300 300 300 300 300 300 \
1000 1000 1000 1000 1000 1000 1000 1000 1000 \
3000 3000 3000 3000 3000 3000 3000 3000 3000 \
)
CACHE_SIZE=${CACHE_SIZES[$index]}
T_LOWS=(\
0.3 0.3 0.3 0.1 0.1 0.1 0.03 0.03 0.03 \
0.3 0.3 0.3 0.1 0.1 0.1 0.03 0.03 0.03 \
0.3 0.3 0.3 0.1 0.1 0.1 0.03 0.03 0.03 \
0.3 0.3 0.3 0.1 0.1 0.1 0.03 0.03 0.03 \
)
T_LOW=${T_LOWS[$index]}
P_HIGHS=(\
1.0 0.1 0.01 1.0 0.1 0.01 1.0 0.1 0.01 \
1.0 0.1 0.01 1.0 0.1 0.01 1.0 0.1 0.01 \
1.0 0.1 0.01 1.0 0.1 0.01 1.0 0.1 0.01 \
1.0 0.1 0.01 1.0 0.1 0.01 1.0 0.1 0.01 \
)
P_HIGH=${P_HIGHS[$index]}


python filtering/one_pass_heuristic_dedup.py \
    --seed 42 \
    --bucket-size 100 \
    --cache-size $CACHE_SIZE \
    --t-low $T_LOW \
    --t-hig 0.99 \
    --p-low 1.0 \
    --p-high $P_HIGH \
    --stop-idx 4800000 \
    --log-step 4800