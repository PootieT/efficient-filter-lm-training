#!/bin/bash -l

# Set SCC project
#$ -P ds563

# Specify hard time limit for the job.
#   The job will be aborted if it runs longer than this time.
#   The default time is 12 hours
#$ -l h_rt=12:00:00

# Send an email when the job finishes or if it is aborted (by default no email is sent).
######$ -m ea

# Give job a name
#$ -N 'glue-eval'

# Combine output and error files into a single file
#$ -j y
#$ -o log

# request 6 cores, each with 6 GB RAM at least
#$ -pe omp 4
####$ -l mem_per_core=6G

# request 0 GPU
#$ -l gpus=1
#$ -l gpu_c=6.0

# Submit an array job with 5 tasks
#$ -t 1

# Keep track of information related to the current job
echo "=========================================================="
echo "Start date : $(date)"
echo "Job name : $JOB_NAME"
echo "Job ID : $JOB_ID  $SGE_TASK_ID"
echo "=========================================================="
nvidia-smi

module load anaconda3/5.2.0
source activate /projectnb/llamagrp/peter/CS543-final-project/envs
export PYTHONPATH="${PYTHONPATH}:/projectnb/llamagrp/peter/CS543-final-project"
export TRANSFORMERS_CACHE=/projectnb2/llamagrp/peter/huggingface_cache/
export HF_DATASETS_CACHE=/projectnb2/llamagrp/peter/huggingface_cache/

index=$(($SGE_TASK_ID-1))
#index=0

ROOT="/projectnb2/llamagrp/peter/CS543-final-project/dump"
COUNTER=0
for MODEL_PATH in $ROOT/*/pytorch_model.bin; do
  echo "counter=" $COUNTER "file=" $MODEL_PATH
  if [ $COUNTER == $index ]; then
    PARENT_DIR="$(dirname "$MODEL_PATH")"
    BASE_NAME="$(basename "$PARENT_DIR")"
    echo "+++++++++++++ counter=" $COUNTER "file=" $MODEL_PATH "parent_dir=" $PARENT_DIR "+++++++++++++"
    for TASK_NAME in cola sst2 mrpc stsb qqp mnli qnli rte wnli
    do
      if [[ $TASK_NAME == "mrpc" ]] || [[ $TASK_NAME == "wnli" ]]; then
        EPOCHS=5
      else
        EPOCHS=3
      fi

      RUN_NAME=$BASE_NAME-$TASK_NAME
      echo "============= running glue task: ${TASK_NAME} w/ ${EPOCHS} epochs, run-name ${RUN_NAME} ============="
#      python evaluation/run_glue.py \
#        --model_name_or_path $MODEL_PATH \
#        --run_name $RUN_NAME \
#        --task_name $TASK_NAME \
#        --do_train \
#        --do_eval \
#        --max_seq_length 128 \
#        --per_device_train_batch_size 32 \
#        --learning_rate 2e-5 \
#        --num_train_epochs $EPOCHS \
#        --output_dir $PARENT_DIR/$TASK_NAME/
    done
  fi
  let COUNTER++
done
